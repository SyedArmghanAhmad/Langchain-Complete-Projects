{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armghan\\AppData\\Local\\Temp\\ipykernel_7020\\1939626861.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"mistral\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LangChain appears to be a project or tool that is not widely recognized in the general context. However, if we're talking about artificial intelligence (AI) and machine learning (ML), I can provide an example of what a \"LangChain\" could potentially refer to:\n",
      "\n",
      "In the field of AI and ML, it's common for researchers and developers to create language-centric systems or models to process and understand human language. A \"LangChain\" in this context could be a series of linked language models or a comprehensive system that uses multiple language models in a chain-like manner to achieve better performance at various natural language processing tasks, such as translation, summarization, or question answering.\n",
      "\n",
      "Of course, without more specific information about the \"LangChain\" you're referring to, it is difficult to say exactly what it is. It's essential to do more research on the project or tool in question for a precise understanding of its purpose and functionality.\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "#from langchain_core.messages import HumanMessage\n",
    "#from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Create an instance of the ChatOllama model\n",
    "#llm = ChatOllama(model=\"mistral\")\n",
    "# Generate a response\n",
    "#response = llm.invoke([HumanMessage(content=\"What is LangChain?\")])\n",
    "\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Understanding Core LangChain Components\n",
    "\n",
    "LangChain is built around modular components that you can mix and match. We'll cover:\n",
    "\n",
    "\n",
    "1️⃣ Chat Models – Using Mistral to generate text\n",
    "\n",
    "2️⃣ Messages – Structuring user & system prompts\n",
    "\n",
    "3️⃣ Prompts – Creating effective LLM inputs\n",
    "\n",
    "4️⃣ Output Parsers – Structuring LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI, or Artificial Intelligence, is a broad field focused on creating intelligent machines that can perform tasks that typically require human intelligence, such as recognizing speech, making decisions, or solving problems.\n",
      "\n",
      "Machine Learning (ML), on the other hand, is a subset of AI that uses statistical methods to enable machines to improve their performance on a specific task over time without being explicitly programmed. Essentially, Machine Learning algorithms learn from data, identify patterns and make decisions based on those patterns. In this way, machine learning allows AI systems to adapt and improve their performance with more experience or exposure to data.\n"
     ]
    }
   ],
   "source": [
    "#Using Chat Models in LangChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Load Mistral via Ollama\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "# Define a system message (for behavior control)\n",
    "\n",
    "system_message = SystemMessage(content=\"You are an AI assistant that provides concise answers.\")\n",
    "\n",
    "# Human user input\n",
    "\n",
    "user_message = HumanMessage(content=\"What is the difference between AI and Machine Learning?\")\n",
    "\n",
    "# Use the LLM to generate a response\n",
    "response = llm.invoke([system_message, user_message])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Terms:   Quantum Computing, put simply, is a type of computation that uses the principles of quantum mechanics to process information. Unlike classical computers that use bits (0s and 1s) to store and manipulate data, quantum computers use quantum bits, or qubits.\n",
      "\n",
      "Qubits can exist in multiple states at once—a phenomenon known as superposition. This means a qubit can be both 0 and 1 simultaneously until observed, which allows for parallel processing of many computations at once.\n",
      "\n",
      "Another fascinating feature of quantum computing is entanglement, where two or more qubits become interconnected so that the state of one instantaneously affects the other, regardless of distance. This property enables complex problem-solving capabilities beyond those achievable by classical computers.\n",
      "\n",
      "Quantum computers have the potential to solve certain complex problems much faster than classical computers, such as simulating molecular structures for drug discovery or breaking modern encryption methods. However, building and maintaining a stable quantum computer is extremely challenging due to factors like decoherence (loss of quantum coherence) and error correction. Despite these challenges, researchers continue to push the boundaries of what's possible with this exciting technology.\n",
      "for a 5 year old:   Sure, let's imagine you are playing with your toy blocks at home. Usually, when you build something, you have to put one block on top of another in a specific way for it to hold up. In the traditional computer, we can only use these blocks (which represent data as 0s and 1s) one at a time, following certain rules.\n",
      "\n",
      "But what if I gave you magic toy blocks that could be both 'on' and 'off' or 'yes' and 'no' at the same time? That would mean you can build much more complex structures than before! This is similar to how quantum computers work. Instead of using traditional bits (0s and 1s), they use something called qubits, which can be in multiple states simultaneously.\n",
      "\n",
      "This ability allows a quantum computer to process information much faster than classical computers for certain tasks, just like how building with magic blocks could let you build a castle in no time compared to using regular toy blocks! But remember, we still have a lot to learn about these magical toy blocks and how they can be used best. So scientists are working hard to make quantum computers more powerful and practical for everyday use!\n"
     ]
    }
   ],
   "source": [
    "#2️⃣ Prompt Engineering: Controlling Responses\n",
    "\n",
    "prompt1 = HumanMessage(content=\"Explain quantum computing in simple terms.\")\n",
    "prompt2 = HumanMessage(content=\"Explain quantum computing like I'm 5 years old.\")\n",
    "\n",
    "# Use the LLM to generate responses\n",
    "\n",
    "response1 = llm.invoke([prompt1])\n",
    "response2 = llm.invoke([prompt2])\n",
    "\n",
    "print(\"Simple Terms: \",response1.content)\n",
    "print(\"for a 5 year old: \",response2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" Quantum Computing, put simply, is a type of computation that uses the principles of quantum mechanics to process information. Unlike classical computers that use bits (0s and 1s) to store and manipulate data, quantum computers use quantum bits, or qubits.\\n\\nQubits can exist in multiple states at once—a phenomenon known as superposition. This means a qubit can be both 0 and 1 simultaneously until observed, which allows for parallel processing of many computations at once.\\n\\nAnother fascinating feature of quantum computing is entanglement, where two or more qubits become interconnected so that the state of one instantaneously affects the other, regardless of distance. This property enables complex problem-solving capabilities beyond those achievable by classical computers.\\n\\nQuantum computers have the potential to solve certain complex problems much faster than classical computers, such as simulating molecular structures for drug discovery or breaking modern encryption methods. However, building and maintaining a stable quantum computer is extremely challenging due to factors like decoherence (loss of quantum coherence) and error correction. Despite these challenges, researchers continue to push the boundaries of what's possible with this exciting technology.\" additional_kwargs={} response_metadata={'model': 'mistral', 'created_at': '2025-02-09T14:20:48.4851332Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 37227134700, 'load_duration': 14660100, 'prompt_eval_count': 13, 'prompt_eval_duration': 832000000, 'eval_count': 249, 'eval_duration': 36379000000} id='run-236a500e-016a-4918-92b5-2be4279d3aec-0'\n"
     ]
    }
   ],
   "source": [
    "#3️⃣ Output Parsers: Structuring Responses\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#load parser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Parse the LLM response\n",
    "parsed_response = parser.parse(response1)\n",
    "\n",
    "print(parsed_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Chaining LLM Calls\n",
    "\n",
    "LangChain allows us to connect multiple steps together, making workflows more dynamic.\n",
    "\n",
    "\n",
    "Types of Chains in LangChain\n",
    "\n",
    "1️⃣ Simple Sequential Chains – One LLM output becomes the next input\n",
    "\n",
    "2️⃣ Sequential Chains with Logic – Add intermediate processing steps\n",
    "\n",
    "3️⃣ LLM + Tools – Combine LLMs with external APIs, vector stores, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Gadget Idea:  Title: Holo-Spectra: Augmented Reality Sensory Interface and Holographic Communication Device\n",
      "\n",
      "Description:\n",
      "\n",
      "Holospectra is an innovative, wearable, and versatile Augmented Reality (AR) device that seamlessly merges the digital world with our physical environment to create a unique sensory experience. It offers immersive, intuitive, and real-time interaction through holographic projections, tactile feedback, and advanced biometric sensors.\n",
      "\n",
      "Key Features:\n",
      "\n",
      "1. Holographic Projections: Holospectra projects high-definition 3D images onto the user's field of vision, allowing them to interact with digital content as if it were physically present in their environment. This feature enhances productivity, entertainment, and communication by creating a more immersive and interactive experience.\n",
      "\n",
      "2. Tactile Feedback System: The device is equipped with advanced tactile feedback technology that allows users to feel textures, shapes, and even temperatures of virtual objects within their holographic environment. This provides an unprecedented level of realism and engagement in AR applications.\n",
      "\n",
      "3. Biometric Sensors: Holospectra features a suite of biometric sensors that monitor the user's physiological responses to optimize the device's performance, ensuring a comfortable and efficient experience. The sensors can detect changes in heart rate, sweat levels, eye movements, and even brain activity, enabling the device to adapt its settings dynamically to best suit the user's needs.\n",
      "\n",
      "4. Cross-Platform Connectivity: Holospectra is designed with universal compatibility in mind, allowing it to interface seamlessly with a wide range of devices, platforms, and applications. This makes it an essential tool for professionals across various industries, such as healthcare, education, entertainment, and more.\n",
      "\n",
      "5. Advanced Voice Recognition and Natural Language Processing: The device is equipped with cutting-edge voice recognition technology that enables users to control their digital environment using simple spoken commands. Additionally, Holospectra incorporates advanced natural language processing algorithms to facilitate easy and intuitive communication between users, both in virtual and real-world environments.\n",
      "\n",
      "6. Portable Design: To cater to the demands of an increasingly mobile world, Holospectra is designed with a lightweight, compact form factor that allows users to take their digital environment with them wherever they go. The device can be worn as glasses, a headband, or even integrated into clothing for maximum convenience and comfort.\n",
      "\n",
      "7. Integrated AI Assistant: An intelligent AI assistant powers Holospectra, helping users manage their schedules, access information, and complete tasks more efficiently. The assistant learns from the user's behavior to provide personalized recommendations and adaptive support.\n",
      "\n",
      "Holospectra represents a significant leap forward in AR technology, offering an immersive, intuitive, and versatile solution for professionals, enthusiasts, and everyday users alike. Its advanced features and cutting-edge design make it an essential tool for the digital age.\n",
      "\n",
      "📜 Detailed Description:  Title: Holo-Spectra: Augmented Reality Sensory Interface and Holographic Communication Device\n",
      "\n",
      "Holospectra is a revolutionary, wearable, and versatile Augmented Reality (AR) device that integrates the digital world with our physical environment to create an unparalleled sensory experience. It offers immersive, intuitive, and real-time interaction through holographic projections, tactile feedback, and advanced biometric sensors.\n",
      "\n",
      "Key Features:\n",
      "\n",
      "1. Holographic Projections (HP): The Holospectra device projects high-definition 3D images into the user's field of vision. This enables users to interact with digital content as if it were physically present in their environment. The HP feature enhances productivity, entertainment, and communication by creating a more immersive and interactive experience.\n",
      "\n",
      "2. Tactile Feedback System (TFS): The device is equipped with an advanced tactile feedback system that allows users to feel textures, shapes, and even temperatures of virtual objects within their holographic environment. This provides an unprecedented level of realism and engagement in AR applications by enhancing the sense of touch.\n",
      "\n",
      "3. Biometric Sensors (BS): Holospectra features a suite of biometric sensors that monitor the user's physiological responses to optimize device performance and ensure a comfortable experience. These sensors can detect changes in heart rate, sweat levels, eye movements, and brain activity, enabling the device to adapt its settings dynamically based on user needs.\n",
      "\n",
      "4. Cross-Platform Connectivity (CPC): Designed with universal compatibility, Holospectra can seamlessly interface with a wide range of devices, platforms, and applications. This versatility makes it an essential tool for professionals across various industries such as healthcare, education, entertainment, and more.\n",
      "\n",
      "5. Advanced Voice Recognition and Natural Language Processing (VR/NLP): Holospectra incorporates cutting-edge voice recognition technology that allows users to control their digital environment using simple spoken commands. The device's advanced NLP algorithms facilitate easy and intuitive communication between users, both in virtual and real-world environments.\n",
      "\n",
      "6. Portable Design (PD): To cater to a mobile world, Holospectra is designed with a lightweight, compact form factor that enables users to take their digital environment with them wherever they go. The device can be worn as glasses, a headband, or even integrated into clothing for maximum convenience and comfort.\n",
      "\n",
      "7. Integrated AI Assistant (IAA): An intelligent AI assistant powers Holospectra, helping users manage their schedules, access information, and complete tasks more efficiently. The assistant learns from the user's behavior to provide personalized recommendations and adaptive support.\n",
      "\n",
      "Holospectra signifies a significant advancement in AR technology, offering an immersive, intuitive, and versatile solution for professionals, enthusiasts, and everyday users alike. Its innovative features and cutting-edge design make it an essential tool for the digital age, bridging the gap between reality and virtuality with seamless integration and unparalleled sensory experiences.\n"
     ]
    }
   ],
   "source": [
    "#Chaining LLM Calls\n",
    "#1️⃣ Simple Sequential Chain (Basic Flow)\n",
    "#We’ll first connect two prompts in a single pipeline.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "#First prompt: we'll generate an idea for a futuristic gadget\n",
    "prompt1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an expert tech innovator.\"),\n",
    "    (\"human\",\"Generate an idea for a futuristic gadget.\"),\n",
    "])\n",
    "\n",
    "#Second prompt: we'll generate a detailed description of the gadget\n",
    "\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional tech reviewer.\"),\n",
    "    (\"human\", \"Explain the features of {gadget_idea} in detail.\"),\n",
    "])\n",
    "\n",
    "# Define LLM Chains\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1, output_key=\"gadget_idea\")  # ✅ Explicit output key\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2, output_key=\"description\")  # ✅ Explicit output key\n",
    "\n",
    "# Define SequentialChain (handles multiple inputs/outputs)\n",
    "full_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[],  # ✅ No initial input required\n",
    "    output_variables=[\"gadget_idea\", \"description\"],  # ✅ Correct output mapping\n",
    ")\n",
    "\n",
    "# Run the entire pipeline\n",
    "response = full_chain.invoke({})  # ✅ Invoke without input\n",
    "\n",
    "# Print results\n",
    "print(\"🚀 Gadget Idea:\", response[\"gadget_idea\"])\n",
    "print(\"\\n📜 Detailed Description:\", response[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📰 News Summary:  On February 9, 2025, the world witnessed a groundbreaking development in renewable energy as the International Space Solar Power (ISSP) Project successfully launched its first solar power satellite into orbit. The project aims to harness solar energy in space and transmit it wirelessly back to Earth, potentially providing unlimited clean energy without geographical limitations. This is seen as a significant step towards addressing climate change and meeting global energy demands sustainably. The launch took place from the NASA Kennedy Space Center in Florida with countries worldwide expressing enthusiasm about this collaborative effort to build a more sustainable future.\n"
     ]
    }
   ],
   "source": [
    "#3️⃣ LLM + Tools (Calling APIs)\n",
    "from datetime import datetime\n",
    "\n",
    "# Current date and time\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "# Use the date in an LLM prompt\n",
    "prompt3 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a news analyst.\"),\n",
    "    (\"human\", f\"Summarize a major world event happening on {today_date}.\"),\n",
    "])\n",
    "chain3 = LLMChain(llm=llm, prompt=prompt3)\n",
    "\n",
    "response = chain3.invoke({})\n",
    "print(\"\\n📰 News Summary:\", response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Simple RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 5 text chunks!\n"
     ]
    }
   ],
   "source": [
    "#1️⃣ Load & Chunk Text Data\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Load a text document\n",
    "loader = TextLoader(\"my document.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the text into chunks\n",
    "# Split into smaller chunks for better retrieval\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"✅ Loaded {len(chunks)} text chunks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector database created!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Generate embeddings using Ollama\n",
    "embedding_model = OllamaEmbeddings(model=\"mistral\")\n",
    "\n",
    "# Store the chunks in a FAISS vector database\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "print(\"✅ Vector database created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📖 Answer:  The main idea of the document is that transitioning to a more sustainable future by integrating multiple renewable energy sources and improving energy storage capabilities is essential for meeting global energy demands, benefiting the environment, creating jobs, strengthening economies, and ensuring energy security for future generations. Government policies and investments, as well as private sector investment, are key drivers in this transition, with improvements in battery technology, solar energy, wind energy, hydroelectric power, and other renewable sources playing a significant role. The document also emphasizes the challenges in energy storage and mentions hydrogen fuel cells and innovations like small-scale hydro and tidal energy as potential solutions.\n"
     ]
    }
   ],
   "source": [
    "#Query the Knowledge Base with Mistral\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "# Create a retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Define a RAG prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that answers questions based on provided documents.\"),\n",
    "    (\"human\", \"Answer this using the most relevant document: {context}. Question: {question}\")\n",
    "])\n",
    "\n",
    "# Create RAG-powered QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=retriever)\n",
    "\n",
    "# Ask a question!\n",
    "query = \"What is the main idea of the document?\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"\\n📖 Answer:\", response[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📖 Answer:  The text discusses the transition towards a sustainable future through the adoption of various renewable energy sources and improving energy storage capabilities. Challenges in renewable energy adoption, particularly energy storage, are being addressed with improvements in battery technology and the emergence of hydrogen fuel cells. Solar energy advancements include high-efficiency photovoltaic cells and cost-effective solar panels made from recycled materials, while wind energy continues to expand with efficient turbines that generate power at low wind speeds. Hydroelectric power remains reliable, with innovations in small-scale hydro and tidal energy. The document highlights the importance of government policies and investments, such as incentives, tax credits, and research funding, in driving the adoption of renewable energy. The private sector is also investing heavily in clean energy, leading to competition and rapid technological advancements.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question!\n",
    "query = \"Summarize the document\"\n",
    "response = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"\\n📖 Answer:\", response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Orchestrating Mistral with LangChain\n",
    "Now that we have RAG, let’s improve our setup with:\n",
    "\n",
    "✅ Chaining components (RAG + memory + structured output)\n",
    "\n",
    "✅ Callbacks for logging/debugging\n",
    "\n",
    "✅ Efficient query processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ Multi-Step Chains: Query Analysis + RAG\n",
    "\n",
    "Instead of just retrieving docs, let’s first analyze the query, then decide whether to:\n",
    "\n",
    "1️⃣ Retrieve data from the knowledge base\n",
    "\n",
    "2️⃣ Answer directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📖 Answer: content=' Title: \"Sustainable Development Goals (SDGs) and the Role of Higher Education\"\\n\\nThe document discusses the role and responsibilities of higher education institutions in achieving the United Nations Sustainable Development Goals (SDGs). It highlights that universities play a critical role in fostering sustainable development due to their role as knowledge producers, research facilities, and educators. The document emphasizes that higher education can contribute significantly by promoting interdisciplinary learning, conducting impactful research, and engaging with communities for sustainable development.\\n\\nThe text provides examples of how institutions have integrated the SDGs into their curriculum, research, and operations. It also mentions challenges such as insufficient resources, lack of political will, and inadequate monitoring mechanisms that need to be addressed for effective implementation. The document suggests strategies for universities to strengthen their commitment towards sustainable development, including creating cross-institutional collaborations, developing SDG action plans, fostering partnerships with the private sector, and promoting public engagement.\\n\\nThe text concludes by emphasizing that higher education institutions must take a proactive role in contributing to the achievement of the SDGs for a more sustainable future. It calls on universities worldwide to integrate the SDGs into their core mission and operations, fostering graduates equipped with knowledge, skills, and values necessary for sustainable development.' additional_kwargs={} response_metadata={'model': 'mistral', 'created_at': '2025-02-09T16:17:44.0546464Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 40535720400, 'load_duration': 11784100, 'prompt_eval_count': 11, 'prompt_eval_duration': 802000000, 'eval_count': 281, 'eval_duration': 39720000000} id='run-b996c166-27c4-4960-9d3d-d081b11cad13-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "#from langchain_core.chains import LLMChain\n",
    "#from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Load Mistral\n",
    "#llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "# Step 1: Query Analysis Chain\n",
    "query_analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Classify the following question:\\n{query}\\n\\nType:\\n- 'knowledge' if it needs retrieval\\n- 'general' if the LLM can answer directly\"\n",
    ")\n",
    "\n",
    "query_analysis_chain = LLMChain(llm=llm, prompt=query_analysis_prompt)\n",
    "\n",
    "# Step 2: RAG-Powered Answering\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=vector_store.as_retriever())\n",
    "\n",
    "# Process a query\n",
    "query = \"Summarize the document.\"\n",
    "query_type = query_analysis_chain.invoke({\"query\": query})[\"text\"]\n",
    "\n",
    "if \"knowledge\" in query_type.lower():\n",
    "    response = qa_chain.invoke({\"question\": query, \"chat_history\": []})\n",
    "\n",
    "else:\n",
    "    response = llm.invoke(query)\n",
    "\n",
    "print(\"\\n📖 Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Callbacks: Debug & Log Every Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "As the world moves towards a more sustainable future, integrating multiple renewable energy sources and improving energy storage capabilities will be essential for meeting global energy demands. The transition to green energy not only benefits the environment but also creates jobs, strengthens economies, and ensures energy security for future generations.\n",
      "\n",
      "One of the biggest challenges in renewable energy adoption is energy storage. Battery technology, such as lithium-ion and solid-state batteries, is constantly improving to store excess energy for later use. Hydrogen fuel cells are also emerging as a viable solution for long-term energy storage.\n",
      "\n",
      "Government policies and investments play a crucial role in accelerating the adoption of renewable energy. Incentives, tax credits, and funding for research and development are driving innovation in this sector. The private sector is also investing heavily in clean energy, leading to increased competition and rapid technological advancements.\n",
      "\n",
      "Solar energy has seen significant breakthroughs, including high-efficiency photovoltaic cells and the use of recycled materials to create cost-effective solar panels. Wind energy continues to expand with larger and more efficient turbines capable of generating power even at low wind speeds. Hydroelectric power remains a reliable source of energy, with innovative technologies like small-scale hydro and tidal energy gaining traction.\n",
      "Human: What are the key takeaways?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "# Create a callback handler\n",
    "handler = StdOutCallbackHandler()\n",
    "\n",
    "# Apply the callback handler to the chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=vector_store.as_retriever(), callbacks=[handler])\n",
    "\n",
    "\n",
    "# Run with logging\n",
    "query = \"What are the key takeaways?\"\n",
    "response = qa_chain.invoke({\"question\": query, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3️⃣ Caching for Faster Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "# Enable in-memory caching\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# Now, repeated queries will be **much faster**!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
