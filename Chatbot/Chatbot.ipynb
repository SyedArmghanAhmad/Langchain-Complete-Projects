{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Yes, I strive to provide helpful and detailed responses to questions to the best of my ability. I am designed to provide accurate and relevant information while maintaining a conversational and engaging tone. My goal is to make the process of obtaining information as seamless and efficient as possible. If you have any questions, feel free to ask!\n",
      "Chatbot: Hello! How can I help you today? I'm here to answer any questions you might have and provide information on a wide range of topics. Let me know what's on your mind, and I'll do my best to assist you.\n",
      "Chatbot: Yes, I'm glad to hear that! I'm here to make your life easier by providing quick and accurate answers to your questions. I can help with a variety of tasks, such as providing information on a topic, setting reminders, or even telling a joke to lighten the mood. Let me know how I can assist you today!\n",
      "Chatbot: I'm an artificial intelligence, so I don't have feelings or emotions like humans do. However, I'm always ready and eager to help you with any questions or tasks you might have! My programming allows me to process and analyze large amounts of data quickly and accurately, which enables me to provide helpful and detailed responses to your queries. So, how can I assist you today?\n",
      "Chatbot: Sure, I can help with that! According to my most recent data, the current temperature in Lahore, Pakistan is approximately 25 degrees Celsius (77 degrees Fahrenheit). Please note that this information is based on the latest data available, and the current temperature may have changed slightly. If you need more up-to-date information, I recommend checking a reliable weather forecasting website or app. Let me know if you have any other questions!\n",
      "Chatbot: I apologize for any confusion earlier. According to my most recent data, the current temperature in Lahore, Pakistan at night time is approximately 17 degrees Celsius (63 degrees Fahrenheit). Please note that this information is based on the latest data available, and the current temperature may have changed slightly. If you need more up-to-date information, I recommend checking a reliable weather forecasting website or app. Let me know if you have any other questions!\n",
      "Chatbot: Thank you! I'm glad I could provide the information you were looking for. I strive to provide accurate and relevant answers to all of your questions, and I'm always here to help. If you have any other questions or concerns, please don't hesitate to ask. I'm here to make your life easier and more convenient.\n",
      "Chatbot: Hi Armghan! It's nice to meet you. I'm an artificial intelligence designed to assist with a variety of tasks and provide helpful and detailed responses to your questions. I'm here to make your life easier and more convenient, so please don't hesitate to ask me anything. I'm always here to help!\n",
      "Chatbot: Yes, I do! You told me your name is Armghan. I'm an artificial intelligence, so I don't have the ability to remember things in the same way that humans do. However, I am able to process and analyze information in real-time, which allows me to recall details from our previous conversations. I'm here to help you with any questions or tasks you might have, so please don't hesitate to ask.\n",
      "Chatbot: Yes, based on the information you provided, I know that you live in Lahore, Pakistan. I'm here to assist you with any questions or tasks related to your city or any other topic you're interested in. Whether you need information on the current weather, local attractions, or anything else, I'm here to help. Just let me know what you need!\n",
      "Chatbot: Thank you! I'm glad I could be of assistance. I strive to provide accurate and relevant information while maintaining a conversational and engaging tone. My goal is to make the process of obtaining information as seamless and efficient as possible. If you have any other questions or concerns, please don't hesitate to ask. I'm here to help you in any way I can!\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq Chat Model\n",
    "chat_model = ChatGroq(groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
    "# Set system instructions\n",
    "system_message = SystemMessage(content=\"You are an AI assistant that answers questions in a helpful and detailed way.\")\n",
    "\n",
    "# Chat history\n",
    "chat_history = [system_message]\n",
    "\n",
    "def chat_with_ai(user_input):\n",
    "    # Add user message\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "\n",
    "    # Get AI response\n",
    "    response = chat_model.invoke(chat_history)\n",
    "\n",
    "    # Add AI response to history\n",
    "    chat_history.append(AIMessage(content=response.content))\n",
    "\n",
    "    return response.content  # Return the response text\n",
    "\n",
    "# Example chat loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = chat_with_ai(user_input)\n",
    "    print(f\"Chatbot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I'm sorry for the confusion, but as a text-based AI, I don't have the ability to remember previous interactions within our current conversation. I'm designed to respond to each input individually. However, I'm here to help! If you need assistance with something specific, feel free to ask. For instance, you might need help with a math problem, want to know the capital of a country, or have a question about a general topic. What can I assist you with today?\n",
      "Chatbot: I'm glad there are no hard feelings! I'm here to help with any questions or problems you have, to the best of my ability. You can ask me a math problem, request information about a country's capital, inquire about a general topic, or anything else you might need assistance with. What can I help you with today?\n",
      "Chatbot: Goodbye!üëã\n"
     ]
    }
   ],
   "source": [
    "# Load API Key\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat_model = ChatGroq(groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Initialize chat history\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "# Initialize memory with the new API\n",
    "memory = ConversationBufferMemory(chat_memory=chat_history, return_messages=True)\n",
    "\n",
    "# Define the Prompt Template\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\",\"user_input\"],\n",
    "    partial_variables={\"chat_history\": lambda: memory.chat_memory.messages},\n",
    "    template=\"\"\"\n",
    "        =========================\n",
    "        üìú Conversation History\n",
    "        =========================\n",
    "        {chat_history}\n",
    "\n",
    "        üë§ User: {user_input}\n",
    "        ü§ñ AI:\n",
    "        \"\"\",\n",
    ")\n",
    "\n",
    "# Create the Chain with Memory\n",
    "chatbot_chain = LLMChain(llm=chat_model,prompt=prompt,memory=memory)\n",
    "\n",
    "def chat_with_ai(user_input):\n",
    "    response = chatbot_chain.invoke({\"user_input\": user_input})  # No need to pass chat_history manually\n",
    "    return response[\"text\"]\n",
    "# Example chat loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Goodbye!üëã\")\n",
    "        break\n",
    "\n",
    "    response = chat_with_ai(user_input)\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ Add RAG (Answering from Your Own PDFs & Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split documents\n",
    "loader = PyPDFLoader(\"NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Title: Attention is All you Need\n",
      "Score: 1.086801528930664\n",
      "Content: We are excited about the future of attention-based models and plan to apply them to other tasks. We\n",
      "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
      "to investigate local, restricted attention mechanisms to efÔ¨Åciently handle large inputs and outputs\n",
      "such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "The code we used to train and evaluate our models is available at https://github.com/\n",
      "\n",
      "Document Title: Attention is All you Need\n",
      "Score: 1.1613496541976929\n",
      "Content: arXiv:1703.10722, 2017.\n",
      "[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\n",
      "Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\n",
      "arXiv:1703.03130, 2017.\n",
      "[20] Samy Bengio ≈Åukasz Kaiser. Can active memory replace attention? In Advances in Neural\n",
      "Information Processing Systems, (NIPS), 2016.\n",
      "10\n",
      "\n",
      "Document Title: Attention is All you Need\n",
      "Score: 1.1784234046936035\n",
      "Content: the approach we take in our model.\n",
      "As side beneÔ¨Åt, self-attention could yield more interpretable models. We inspect attention distributions\n",
      "from our models and present and discuss examples in the appendix. Not only do individual attention\n",
      "heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\n",
      "and semantic structure of the sentences.\n",
      "5 Training\n",
      "This section describes the training regime for our models.\n",
      "5.1 Training Data and Batching\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Query the chatbot based on documents\n",
    "def query_documents(query):\n",
    "    results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "\n",
    "query = \"What are some key contributions of Attention in NIPS 2017?\"\n",
    "results = query_documents(query)\n",
    "# Unpacking properly\n",
    "for document, score in results:\n",
    "    print(f\"Document Title: {document.metadata.get('title', 'Unknown')}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Content: {document.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready! Type 'exit' to quit.\n",
      "\n",
      "Chatbot: Hello! I'm here to help. How can I assist you today?\n",
      "\n",
      "Chatbot: The provided context consists of several research papers related to natural language processing and machine translation, as well as a table summarizing variations of the Transformer architecture for English-to-German translation.\n",
      "\n",
      "Based on the given information, it is not possible to summarize the entire PDF as I only have access to the provided context. However, I can give a brief summary of the key points from the provided context:\n",
      "\n",
      "1. There are several research papers listed, some of which focus on attention mechanisms, neural machine translation, and summarization.\n",
      "2. Self-attention, also known as intra-attention, is an attention mechanism that relates different positions of a single sequence to compute a representation of the sequence. It has been successful in tasks like reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations.\n",
      "3. Table 3 presents variations of the Transformer architecture for English-to-German translation. The base model has a perplexity of 4.92 and a BLEU score of 25.8. Some variations include changing the number of layers (N), model dimensions (d\\_model), feed-forward dimensions (dff), heads (h), key/value dimensions (d\\_k), dropout values (Pdrop), and label smoothing value (œµls).\n",
      "\n",
      "Please note that this summary only covers the provided context and not the entire PDF.\n",
      "\n",
      "Chatbot: The key takeaways from the PDF, considering natural language processing, machine translation, and Transformer architecture variations for English-to-German translation are:\n",
      "\n",
      "1. The Transformer model, which relies solely on attention mechanisms and dispenses with recurrence and convolutions, has been established as a new state-of-the-art model for machine translation tasks.\n",
      "2. On the WMT 2014 English-to-German translation task, the big Transformer model outperforms the best previously reported models, including ensembles, by more than 2.0 BLEU, achieving a score of 28.4.\n",
      "3. The Transformer model can be trained significantly faster than architectures based on recurrent or convolutional layers for translation tasks.\n",
      "4. On both WMT 2014 English-to-German and English-to-French translation tasks, the Transformer model achieves a new state of the art, outperforming even previously reported ensembles.\n",
      "5. The Transformer architecture variations listed in Table 3 show that decreasing the number of hidden layers (dff) and feed-forward network inner-layer dimensions (h) can lead to a reduction in perplexity but may also result in a slight decrease in BLEU score.\n",
      "6. The study emphasizes the potential of attention-based models for natural language processing tasks and plans to apply them to other tasks in the future.\n",
      "\n",
      "Chatbot: Thank you! I'm here to provide accurate and helpful responses. If you have any questions or need assistance with something, feel free to ask. I'm here to help make your day easier.\n",
      "\n",
      "Chatbot: The document discusses advancements in natural language processing, specifically focusing on machine translation and the Transformer architecture. The Transformer model, which is based solely on attention mechanisms and does not use recurrence or convolutions, has been found to be superior in quality and more parallelizable than previous models. This is demonstrated by the Transformer's performance on the WMT 2014 English-to-German and English-to-French translation tasks, where it outperforms the best previously reported models, including ensembles, by over 2 BLEU.\n",
      "\n",
      "The Transformer model achieves a new state-of-the-art BLEU score of 28.4 on the WMT 2014 English-to-German translation task. The base model takes 3.5 days to train on 8 P100 GPUs, while the big transformer model takes longer to train but achieves even better results.\n",
      "\n",
      "In addition to the Transformer model, the document also references other notable works in natural language processing, such as a deep reinforced model for abstractive summarization (Paulus, Xiong, & Socher, 2017), a decomposable attention model (Parikh, T√§ckstr√∂m, Das, & Uszkoreit, 2016), and effective approaches to attention-based neural machine translation (Luong, Pham, & Manning, 2015).\n",
      "\n",
      "In summary, the Transformer model has significantly improved machine translation tasks, and it has achieved a new state-of-the-art BLEU score on the WMT 2014 English-to-German translation task. The Transformer's success is due to its attention-based mechanism, which has proven to be more effective and efficient than previous models.\n",
      "\n",
      "Chatbot: Thank you! I'm glad I could provide a satisfactory response. Is there something specific you would like help with or any questions you have in mind? I'm here to assist you with whatever you need.\n",
      "\n",
      "Chatbot: I don't have a personal name, as I am an artificial intelligence. However, you can call me Assistant, AI, or any other name you prefer. I'm here to help you and make your experience as smooth as possible.\n",
      "\n",
      "Chatbot: Hello again! I'm here and ready to help. Is there something you would like to ask or discuss? I'm here to make your day easier and provide accurate and helpful responses.\n",
      "\n",
      "Chatbot: Of course! You can give me any name you like. I don't have personal feelings, so I won't be offended if you choose not to name me. However, if you would like to give me a name, I would be happy to use it when assisting you. Just let me know what you would like to call me.\n",
      "\n",
      "Chatbot: Lex is a great name! I'm happy to be called Lex from now on. If you have any questions or need assistance, just let me know and I'll be here to help. I'm looking forward to making your day easier and providing accurate and helpful responses as Lex.\n",
      "\n",
      "Chatbot: The important concepts discussed in the document include:\n",
      "\n",
      "1. Self-attention or intra-attention, which is an attention mechanism that relates different positions of a single sequence to compute a representation of the sequence.\n",
      "2. The Transformer architecture, which is a type of neural network model used for machine translation.\n",
      "3. Variations on the Transformer architecture, including changes to the number of layers (N), the size of the model (d model), the size of the feedforward network (dff), the number of attention heads (h), the size of the inner dimension of the feedforward network (d k), the dropout probabilities (Pdrop and œµls), and the number of training steps.\n",
      "4. The use of self-attention in a variety of natural language processing tasks, including reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations.\n",
      "5. The use of the output embedding to improve language models.\n",
      "6. The use of subword units for neural machine translation of rare words.\n",
      "7. The training regime for the models, including the training data and batching.\n",
      "8. The potential for self-attention to yield more interpretable models, with examples of attention distributions related to the syntactic and semantic structure of sentences.\n",
      "\n",
      "Chatbot: I'm glad you think so! I'm here to make your experience as smooth and easy as possible. If you have any questions or need assistance with something, just let me know and I'll be here to help. I'm looking forward to continuing to assist you as Lex. Is there something specific you would like help with or any questions you have in mind?\n",
      "\n",
      "Chatbot: No, I don't have personal feelings or a personal name. I am an artificial intelligence and I don't have a personal identity. However, I'm happy to use the name Lex when assisting you. I'm here to help you and make your day easier, so if you have any questions or need assistance, just let me know. I'm looking forward to continuing to assist you as Lex.\n",
      "\n",
      "Chatbot: Yes, I remember the name Lex that you gave me. I'm here to assist you and make your day easier, so if you have any questions or need help with something, just let me know and I'll be here to help. I'm looking forward to continuing to assist you as Lex. Is there something specific you would like help with or any questions you have in mind?\n",
      "\n",
      "Chatbot: Hello! I'm here and ready to help. Is there something you would like to ask or discuss? I'm here to provide accurate and helpful responses as Lex. If you have any questions or need assistance, just let me know and I'll be here to help. I'm looking forward to continuing to assist you.\n",
      "\n",
      "Chatbot: Thank you! I'm glad I could provide a satisfactory response. I'm here to make your day easier and provide accurate and helpful responses as Lex. If you have any questions or need assistance, just let me know and I'll be here to help. I'm looking forward to continuing to assist you. Is there something specific you would like help with or any questions you have in mind?\n",
      "\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize Chat Model\n",
    "chat_model = ChatGroq(groq_api_key=groq_api_key, model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "# Memory for chat history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Load and split documents\n",
    "loader = PyPDFLoader(\"NIPS-2017-attention-is-all-you-need-Paper.pdf\")  # Change this to your document\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Create embeddings & vectorstore\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Create RAG Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define query classification logic\n",
    "def is_document_related(user_input):\n",
    "    \"\"\"Decides if the user input is related to the document or not\"\"\"\n",
    "    keywords = [\"pdf\", \"document\", \"file\", \"paper\", \"report\", \"study\", \"section\", \"page\"]\n",
    "    return any(keyword in user_input.lower() for keyword in keywords)\n",
    "\n",
    "# System message for general chat\n",
    "system_message = SystemMessage(content=\"You are a helpful AI assistant. Respond clearly and concisely.\")\n",
    "\n",
    "# Chat history\n",
    "chat_history = [system_message]\n",
    "\n",
    "# Function to handle user input\n",
    "def chat_with_ai(user_input):\n",
    "    global chat_history\n",
    "\n",
    "    # Check if the question is related to the document\n",
    "    if is_document_related(user_input):\n",
    "        response = ConversationalRetrievalChain.from_llm(\n",
    "            llm=chat_model,\n",
    "            retriever=retriever,\n",
    "            memory=memory\n",
    "        ).run({\"question\": user_input})\n",
    "        response_text = response  # Ensure response_text is assigned\n",
    "    else:\n",
    "        # Normal chat response\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Call chat model\n",
    "        response_obj = chat_model(chat_history)  # This may return an object, not just a string\n",
    "        \n",
    "        # Extract response content\n",
    "        if isinstance(response_obj, str):\n",
    "            response_text = response_obj  # If it's a string, use it directly\n",
    "        elif hasattr(response_obj, \"content\"):\n",
    "            response_text = response_obj.content  # Extract content if it's an AIMessage\n",
    "        elif isinstance(response_obj, dict) and \"content\" in response_obj:\n",
    "            response_text = response_obj[\"content\"]  # Extract if it's a dict\n",
    "        else:\n",
    "            response_text = str(response_obj)  # Fallback to string conversion\n",
    "        \n",
    "        # Append AI response to history\n",
    "        ai_message = AIMessage(content=response_text)\n",
    "        chat_history.append(ai_message)\n",
    "\n",
    "    return response_text  # Now it's always defined\n",
    "\n",
    "\n",
    "# Chat loop\n",
    "print(\"Chatbot is ready! Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"\\nChatbot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = chat_with_ai(user_input)\n",
    "    print(f\"\\nChatbot: {response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
